{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da2d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "# Path to your JSONL file\n",
    "file_path = \"/project/flame/asetlur/pipeline-rl/0.jsonl\"\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    return text.split(\"<|im_start|>user\\n\")[1].split(\"<|im_end|>\\n<|im_start|>assistant\")[0]\n",
    "\n",
    "def extract_text_and_reward_jsonl(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Stream a big JSONL file where each line is a list of 8 entries.\n",
    "    For each entry, write out {\"text\": ..., \"reward\": ...} as a new line.\n",
    "    \"\"\"\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin, \\\n",
    "         open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "\n",
    "        for line in tqdm(fin, desc=\"Processing rows\"):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Each row is a list of entries (e.g., length 8)\n",
    "            try:\n",
    "                row = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                # optionally log or skip bad lines\n",
    "                continue\n",
    "\n",
    "            row_text = None\n",
    "            row_model_version = None\n",
    "            rewards = []\n",
    "            for entry in row:\n",
    "                # Safely get fields\n",
    "                text = process_text(entry.get(\"text\"))\n",
    "                model_version = entry.get(\"metadata\")[\"model_version\"]\n",
    "\n",
    "                if row_text is None: \n",
    "                    row_text = text\n",
    "                else: \n",
    "                    assert text == row_text\n",
    "                if row_model_version is None:\n",
    "                    row_model_version = model_version\n",
    "                else:\n",
    "                    try:\n",
    "                        assert abs(row_model_version-model_version) <= 1024\n",
    "                    except:\n",
    "                        print(model_version, row_model_version)\n",
    "                        raise AssertionError\n",
    "\n",
    "                rewards.append(entry.get(\"reward\"))\n",
    "            \n",
    "            try:\n",
    "                assert len(rewards) > 0\n",
    "            except:\n",
    "                print(rewards)\n",
    "                raise AssertionError\n",
    "                \n",
    "            assert row_text is not None\n",
    "            assert row_model_version is not None\n",
    "            out_obj = {\"text\": row_text, \"rewards\": rewards, \"model_version\": row_model_version}\n",
    "            fout.write(json.dumps(out_obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "extract_text_and_reward_jsonl(\n",
    "    file_path, \n",
    "    file_path.split(\".\")[0]+\"_processed.jsonl\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e54345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the processed JSONL file as a dataframe\n",
    "df = pd.read_json(\n",
    "    file_path.split(\".\")[0]+\"_processed.jsonl\",\n",
    "    lines=True\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(f\"\\nDataframe shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"CohenQu/POPE-MIX-first_guide-no_guide-0.0-0.64-1024-verl\")\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "# If the dataset has multiple splits, you might need to specify which one\n",
    "# For example: dataset['train'] or dataset['validation']\n",
    "if isinstance(dataset, dict):\n",
    "    # If multiple splits, use the first one (usually 'train')\n",
    "    split_name = list(dataset.keys())[0]\n",
    "    df_hf = dataset[split_name].to_pandas()\n",
    "    print(f\"Dataset has splits: {list(dataset.keys())}\")\n",
    "    print(f\"Using split: {split_name}\")\n",
    "else:\n",
    "    df_hf = dataset.to_pandas()\n",
    "\n",
    "df_hf['text'] = df_hf['prompt'].apply(lambda x: x[0]['content'])\n",
    "\n",
    "\n",
    "print(f\"\\nLoaded {len(df_hf)} rows from Hugging Face\")\n",
    "print(f\"\\nDataframe shape: {df_hf.shape}\")\n",
    "print(f\"\\nColumns: {df_hf.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_hf.head()\n",
    "\n",
    "\n",
    "text_to_data_source = df_hf.groupby('text')['level'].first().to_dict()\n",
    "\n",
    "df['source'] = df['text'].apply(lambda x: text_to_data_source[x])\n",
    "\n",
    "\n",
    "df['all_negative'] = df['rewards'].apply(lambda x: float(sum(x) == 0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f91694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Group by model_version and source, then average all_negative\n",
    "df_plot = df.groupby(['model_version', 'source'])['all_negative'].mean().reset_index()\n",
    "\n",
    "# Pivot to have sources as columns for easier plotting\n",
    "df_pivot = df_plot.pivot(index='model_version', columns='source', values='all_negative')\n",
    "\n",
    "# Sort by model_version to ensure proper ordering for running average\n",
    "df_pivot = df_pivot.sort_index()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Get a colormap for different sources\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(df_pivot.columns)))\n",
    "\n",
    "for i, source in enumerate(df_pivot.columns):\n",
    "    color = colors[i]\n",
    "    # Lighter color for original (reduce alpha and brightness)\n",
    "    light_color = (*color[:3], 0.3)  # Lighter with transparency\n",
    "    # Darker color for smoothed (full opacity)\n",
    "    dark_color = tuple(c * 0.7 for c in color[:3]) + (1.0,)  # Darker version\n",
    "    \n",
    "    x = df_pivot.index\n",
    "    y_original = df_pivot[source]\n",
    "    \n",
    "    # Calculate running average (window size of 3, adjust as needed)\n",
    "    window_size = 10\n",
    "    y_smoothed = y_original.rolling(window=window_size, center=True, min_periods=1).mean()\n",
    "    \n",
    "    # Plot original values in lighter color\n",
    "    plt.plot(x, y_original, marker='o', color=light_color, markersize=3, \n",
    "             label=None, alpha=0.4, linewidth=1)\n",
    "    \n",
    "    # Plot smoothed values in darker color\n",
    "    plt.plot(x, y_smoothed, marker='o', color=dark_color, markersize=4,\n",
    "             label=f'{source}', linewidth=2)\n",
    "\n",
    "plt.xlabel('Model Version')\n",
    "plt.ylabel('Average all_negative')\n",
    "plt.title('all_negative averaged across model_version, per source')\n",
    "plt.legend(title='Source', ncol=2, fontsize=9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4048847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba3b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da273fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b739d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6d443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249e718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90b1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline-rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
